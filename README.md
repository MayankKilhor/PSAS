# Python-Selenium-Automation-System

##Introduction

Like many other methodological innovations, Automation has grown over the years with technological advancements, however very few people take advantage of the libraries and methods available to automate their daily tasks. This paper explores the avenue of automation along with scraping data from the internet. 

Our project aims to encourage and explore the world of automation through the use of two major programming languages and interfaces – Python and Selenium. It explores the most popular libraries implemented by python to perform automation and file manipulation in recent years which include the OS, XML, urlparse and getpass libraries. It also explores selenium which is a free (open-source) automated testing framework used to validate web applications across different browsers and platforms. It intends to create a tool-set driven by automation and web scraping. 

We intend to implement and provide a tool set to users with the purpose of saving multiple webpages, documents and means to access files offline without the need to individually go and save each and every required page manually. The tool set also includes scripts that can be used to scrape weather data, top daily news as well as open multiple links through a simple script. This documentation will also cover our workflow methodologies, explore previous work in the field, provide a Software requirement specification documentation along with the design of the proposed system.

The objectives of the implementation are as follows: 

•	Implementation of a multiple-link opener that automates opening links one-by-one on a browser.

•	Scraping the top news headlines from the google news webpage 

•	Scraping weather information from Open Weather Map 

•	Automate form fill-ups and logins through Facebook login automation 

•	Automatically download the desired number of images corresponding to the keyword and number of images required entered by the user. 

•	Provide a working interface to the user that works on menu-based selection with proper user sanitized inputs.

##Innovation

Work for most people nowadays involves using the internet on a daily basis, however people sometimes need offline web pages and images. They may require to do trivial tasks repeatedly such as open multiple links, download multiple images and so on. They may not have the time required to manually perform multiple searches and operations over the internet. We intend to provide a toolset that can help such people and other students that need to scrape data off the internet and automate their work. This can help improve their efficiency along with lessening their burden. It can also be used by tech enthusiasts to explore the upcoming field of automation through programming.
